working on manually coding a neural network by hand from each neuron in mathematical operations in python

# Notes: 
Activation Functions -> output function will have a different activation function than the hidden layers is to mimic the neuron firing, helps offset 
   -  Examples -> https://www.v7labs.com/blog/neural-networks-activation-functions 
   - Neuron neuron connections can lead to weird properties 
If we just use linear activation function, it will be a linear function. We need a non-linear function to help fit any non-linear data 
Calculating Loss to determine the accuracy of the model 
Optimize to decrease the loss function and fine tuning it 

# Steps 

1. Data fitting 
2. Neuron Layers Training 
3. Activation Function (ReLU, Softmax)
4. Loss Function (Categorical Cross-Entropy)
5. Optimization (not done in this folder)